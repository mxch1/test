{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment group 1: Textual feature extraction and numerical comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module C _(35 points)_ Similarity of word usage across a document\n",
    "\n",
    "Here we'll be building up some code to discover how different terms are utilized similarly across a document. For this, our first task will be to create a word frequency counting function.\n",
    "\n",
    "__C1.__ _(12 points)_ Define a function called `count_words(paragraph, pos = True, lemma = True)` that `return`s a `Counter()` called `frequency`. In `frequency`, each key will consist of a `heading = (text, tag)`, where `text` contains the `word.text` attribute from `spacy` if `lemma = False`, and `word.lemma_` attribute if `True`. Similarly, `tag` should be left empty as `\"\"` if `pos = False` and otherwise contain `word.pos_`. The `Counter()` should simply contain the number of times each `heading` is observed in the `paragraph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/local/Cellar/python/3.7.0/Frameworks/Python.framework/Versions/3.7/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import spacy, json, re\n",
    "\n",
    "nlp = spacy.load(\"en\")\n",
    "\n",
    "def count_words(paragraph, pos = True, lemma = True):\n",
    "    doc = nlp(paragraph)\n",
    "    \n",
    "    frequency = Counter()\n",
    "    for sentence in doc.sents:\n",
    "        for word in sentence:\n",
    "            heading = (word.lemma_ if lemma else word.text, \n",
    "                       word.pos_ if pos else \"\")\n",
    "        \n",
    "            frequency[heading] += 1\n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C2.__ _(8 pts)_ Next, define a function called `book_TDM(book_id, pos = True, lemma = True)` and copy into it the TDM-producing code from __Section 2.1.5.1__ of the lecture notes, now `return`-ing `TDM` and `all_words`. Once copied, modify this function to call `count_words` appropriately, now passing through the user of `book_TDM`'s specified `lemma` and `pos` arguments.\n",
    "\n",
    "To provde your code's function, process `book_id = 84` with both of `pos = True` and `lemma = True` and print out the `TDM`'s `.shape` attribute and the first ten terms in `all_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def book_TDM(book_id, pos = True, lemma = True):\n",
    "    ## load the book\n",
    "    with open(\"./data/books/\"+book_id+\".txt\") as f:\n",
    "        book = f.read().strip()\n",
    "    \n",
    "    ## break the document into paragraphs\n",
    "    paragraphs = re.split(\"\\n\\n+\", book)\n",
    "\n",
    "    ## the 'master' set, keeps track of the words in all documents\n",
    "    all_words = set()\n",
    "\n",
    "    ## store the word frequencies by book\n",
    "    all_doc_frequencies = {}\n",
    "\n",
    "    ## loop over the sentences\n",
    "    for j, paragraph in enumerate(paragraphs):        \n",
    "        frequency = count_words(paragraph, pos = pos, lemma = lemma)\n",
    "        all_doc_frequencies[j] = frequency\n",
    "        doc_words = set(frequency.keys())\n",
    "        all_words = all_words.union(doc_words)\n",
    "\n",
    "    ## create a matrix of zeros: (words) x (documents)\n",
    "    TDM = np.zeros((len(all_words),len(all_doc_frequencies)))\n",
    "    ## fix a word ordering for the rows\n",
    "    all_words = sorted(list(all_words))\n",
    "    ## loop over the (sorted) document numbers and (ordered) words; fill in matrix\n",
    "    for j in all_doc_frequencies:\n",
    "        for i, word in enumerate(all_words):\n",
    "            TDM[i,j] = all_doc_frequencies[j][word]\n",
    "\n",
    "    return(TDM, all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\\n', 'SPACE'),\n",
       " ('\\n  ', 'SPACE'),\n",
       " ('\\n   ', 'SPACE'),\n",
       " ('\\n     ', 'SPACE'),\n",
       " ('\\n                              ', 'SPACE'),\n",
       " (' ', 'SPACE'),\n",
       " ('  ', 'SPACE'),\n",
       " ('    ', 'SPACE'),\n",
       " ('     ', 'SPACE'),\n",
       " ('               ', 'SPACE')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TDM, terms = book_TDM(\"84\", pos = True, lemma = True)\n",
    "terms[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6221, 723)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TDM.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C3.__ _(8 pts)_ Next, your job is to define two functions. The first is `sim(u,v)`, which shoud take two arbitrary numeric vectors and compute/output the cosine similarity, as described in __Section 1.1.2.10__.  \n",
    "\n",
    "The second function is `term_sims(i, TDM)`, which should utilize the first function (`sim`) to output a list of cosine similarity values between the word/row `i` and all others (rows) in the `TDM`. \n",
    "\n",
    "Note: each of these functions can be straightforwardly completed using a single line of code! Exhibit your knowledge of comprehensions and vectorization!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(u,v):\n",
    "    return u.dot(v) / (np.linalg.norm(u) * np.linalg.norm(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_sims(i, TDM):\n",
    "    return [sim(TDM[i,], TDM[sim_i,]) for sim_i in range(TDM.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__C4.__ _(7 pts)_ Finally, your goal now is to a write function, `most_similar(term, terms, TDM, top = 25)`, that utilizes `term_sims` to output a sorted list of the `top = N` terms most similar to one specified (`term`). The output data type should be a list of lists, with each inner list representing information for a similar term as: `[row_ix, similarity, term]`. Once complete, prove your function's utility on a `TDM` produced for `book_id = 84` and exhibit the top 25 similar terms to both of `('monster', 'NOUN')` and `('beautiful', 'ADJ')`.\n",
    "\n",
    "Once computation is complete, comment on the ordered results returned in the markdown cell below. Do you think the algorithm is exhibiting sensible result? What would you do to improve?\n",
    "\n",
    "\\[Hint: to locate the row containing the term of interest, utilize the list `.index()` method in application to the `terms` argument.\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Response._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(term, terms, TDM, top = 25):\n",
    "    term_index = terms.index(term)\n",
    "    sims = term_sims(term_index, TDM)\n",
    "    sims = sorted(enumerate(sims), key = lambda x: x[1], reverse = True)\n",
    "    for sim_i, term_sim in sims[:25]:\n",
    "        print(sim_i, term_sim, terms[sim_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3628 1.0 ('monster', 'NOUN')\n",
      "470 0.3380617018914066 ('asseveration', 'NOUN')\n",
      "1254 0.3380617018914066 ('correct', 'VERB')\n",
      "2048 0.3380617018914066 ('existence', 'VERB')\n",
      "2332 0.3380617018914066 ('formation', 'NOUN')\n",
      "3703 0.3380617018914066 ('mutilate', 'VERB')\n",
      "4243 0.3380617018914066 ('posterity', 'NOUN')\n",
      "28 0.3072240245631793 ('-PRON-', 'PRON')\n",
      "2710 0.30578831486257535 ('hideous', 'ADJ')\n",
      "5 0.2929277805918349 (' ', 'SPACE')\n",
      "1473 0.29277002188455997 ('demoniacal', 'ADJ')\n",
      "2325 0.29277002188455997 ('forgetfulness', 'NOUN')\n",
      "12 0.28811865589289226 ('!', 'PUNCT')\n",
      "5483 0.27909246469593313 ('that', 'ADP')\n",
      "1730 0.2760262237369417 ('down', 'ADV')\n",
      "29 0.27266231928075757 ('.', 'PUNCT')\n",
      "0 0.27092834781732605 ('\\n', 'SPACE')\n",
      "327 0.2680355919935828 ('and', 'CCONJ')\n",
      "5487 0.2665740440836767 ('the', 'DET')\n",
      "3748 0.2548235957188128 ('neck', 'NOUN')\n",
      "1163 0.253546276418555 ('connected', 'ADJ')\n",
      "3718 0.253546276418555 ('narrative', 'NOUN')\n",
      "68 0.250263571622741 (';', 'PUNCT')\n",
      "20 0.2502061289650293 (',', 'PUNCT')\n",
      "2390 0.24641185197683604 ('from', 'ADP')\n"
     ]
    }
   ],
   "source": [
    "most_similar(('monster', 'NOUN'), terms, TDM, top = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "602 0.9999999999999998 ('beautiful', 'ADJ')\n",
      "646 0.40824829046386296 ('beneath', 'ADV')\n",
      "4152 0.37499999999999994 ('picturesque', 'NOUN')\n",
      "4758 0.37499999999999994 ('rotterdam', 'PROPN')\n",
      "5036 0.37499999999999994 ('singularly', 'ADV')\n",
      "6060 0.37499999999999994 ('whence', 'ADV')\n",
      "1462 0.35355339059327373 ('delineate', 'NOUN')\n",
      "1771 0.35355339059327373 ('dun', 'NOUN')\n",
      "2221 0.35355339059327373 ('fifth', 'ADJ')\n",
      "3415 0.35355339059327373 ('luxuriance', 'NOUN')\n",
      "3442 0.35355339059327373 ('mainz', 'PROPN')\n",
      "3462 0.35355339059327373 ('mannheim', 'PROPN')\n",
      "3505 0.35355339059327373 ('meander', 'VERB')\n",
      "4062 0.35355339059327373 ('pearly', 'ADJ')\n",
      "4225 0.35355339059327373 ('populous', 'ADJ')\n",
      "4969 0.35355339059327373 ('shipping', 'NOUN')\n",
      "4993 0.35355339059327373 ('shrivelled', 'ADJ')\n",
      "5238 0.35355339059327373 ('steep', 'ADJ')\n",
      "5262 0.35355339059327373 ('straight', 'ADJ')\n",
      "5893 0.35355339059327373 ('variegate', 'VERB')\n",
      "5946 0.35355339059327373 ('vineyard', 'NOUN')\n",
      "6080 0.35355339059327373 ('whiteness', 'NOUN')\n",
      "6110 0.35355339059327373 ('willowy', 'NOUN')\n",
      "688 0.34299717028501764 ('black', 'ADJ')\n",
      "572 0.33541019662496846 ('bank', 'NOUN')\n"
     ]
    }
   ],
   "source": [
    "most_similar(('beautiful', 'ADJ'), terms, TDM, top = 25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
